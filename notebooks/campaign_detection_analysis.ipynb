{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Campaign Detection with Graph Analysis\n",
    "\n",
    "This notebook demonstrates how to detect coordinated campaigns using network analysis.\n",
    "\n",
    "## Objectives\n",
    "- Build user interaction networks\n",
    "- Detect suspicious communities\n",
    "- Analyze hashtag propagation patterns\n",
    "- Identify bot networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install networkx matplotlib seaborn pandas numpy plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Sample Data\n",
    "\n",
    "Create synthetic social media data for demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample social media posts\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Sample hashtags\n",
    "hashtags = [\n",
    "    '#DigitalIndia', '#MakeInIndia', '#IncredibleIndia', '#ProudIndian',\n",
    "    '#BoycottIndia', '#AntiIndia', '#FakeIndia', '#PropagandaAlert',\n",
    "    '#IndiaFirst', '#JaiHind', '#Technology', '#Innovation'\n",
    "]\n",
    "\n",
    "# Generate users with different behavior patterns\n",
    "def generate_users(n_users=100):\n",
    "    users = []\n",
    "    for i in range(n_users):\n",
    "        # Create different user types\n",
    "        if i < 20:  # Bot accounts\n",
    "            user_type = 'bot'\n",
    "            username = f'user{random.randint(10000, 99999)}'\n",
    "            followers = random.randint(10, 100)\n",
    "        elif i < 30:  # Suspicious accounts\n",
    "            user_type = 'suspicious'\n",
    "            username = f'account{random.randint(1000, 9999)}'\n",
    "            followers = random.randint(50, 500)\n",
    "        else:  # Normal users\n",
    "            user_type = 'normal'\n",
    "            username = f'user_{i}'\n",
    "            followers = random.randint(100, 5000)\n",
    "        \n",
    "        users.append({\n",
    "            'user_id': f'user_{i}',\n",
    "            'username': username,\n",
    "            'followers': followers,\n",
    "            'user_type': user_type\n",
    "        })\n",
    "    return users\n",
    "\n",
    "# Generate posts\n",
    "def generate_posts(users, n_posts=1000):\n",
    "    posts = []\n",
    "    for i in range(n_posts):\n",
    "        user = random.choice(users)\n",
    "        \n",
    "        # Bots and suspicious accounts more likely to use certain hashtags\n",
    "        if user['user_type'] == 'bot':\n",
    "            selected_hashtags = random.choices(\n",
    "                ['#BoycottIndia', '#AntiIndia', '#FakeIndia'], k=random.randint(1, 3)\n",
    "            )\n",
    "        elif user['user_type'] == 'suspicious':\n",
    "            selected_hashtags = random.choices(\n",
    "                ['#BoycottIndia', '#PropagandaAlert', '#AntiIndia'], k=random.randint(1, 2)\n",
    "            )\n",
    "        else:\n",
    "            selected_hashtags = random.choices(hashtags, k=random.randint(0, 2))\n",
    "        \n",
    "        content = f\"Sample post content {' '.join(selected_hashtags)}\"\n",
    "        \n",
    "        # Generate timestamp with clustering for coordinated activity\n",
    "        if user['user_type'] in ['bot', 'suspicious'] and random.random() < 0.7:\n",
    "            # Coordinated posting times\n",
    "            base_time = datetime.now() - timedelta(hours=random.randint(1, 48))\n",
    "            timestamp = base_time + timedelta(minutes=random.randint(-30, 30))\n",
    "        else:\n",
    "            timestamp = datetime.now() - timedelta(hours=random.randint(1, 168))\n",
    "        \n",
    "        posts.append({\n",
    "            'post_id': i,\n",
    "            'user_id': user['user_id'],\n",
    "            'content': content,\n",
    "            'hashtags': selected_hashtags,\n",
    "            'timestamp': timestamp,\n",
    "            'platform': random.choice(['Twitter', 'Reddit', 'YouTube'])\n",
    "        })\n",
    "    \n",
    "    return posts\n",
    "\n",
    "# Generate data\n",
    "users = generate_users(100)\n",
    "posts = generate_posts(users, 1000)\n",
    "\n",
    "# Convert to DataFrames\n",
    "users_df = pd.DataFrame(users)\n",
    "posts_df = pd.DataFrame(posts)\n",
    "\n",
    "print(f\"Generated {len(users)} users and {len(posts)} posts\")\n",
    "print(f\"User types: {users_df['user_type'].value_counts()}\")\n",
    "print(f\"Platforms: {posts_df['platform'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build User Interaction Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build network based on shared hashtags\n",
    "def build_hashtag_network(posts_df):\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Group posts by hashtags\n",
    "    hashtag_users = defaultdict(set)\n",
    "    \n",
    "    for _, post in posts_df.iterrows():\n",
    "        user_id = post['user_id']\n",
    "        for hashtag in post['hashtags']:\n",
    "            hashtag_users[hashtag].add(user_id)\n",
    "    \n",
    "    # Add nodes (users)\n",
    "    for user in users_df['user_id']:\n",
    "        user_info = users_df[users_df['user_id'] == user].iloc[0]\n",
    "        G.add_node(user, \n",
    "                  username=user_info['username'],\n",
    "                  followers=user_info['followers'],\n",
    "                  user_type=user_info['user_type'])\n",
    "    \n",
    "    # Add edges between users who use same hashtags\n",
    "    for hashtag, users_set in hashtag_users.items():\n",
    "        users_list = list(users_set)\n",
    "        for i in range(len(users_list)):\n",
    "            for j in range(i + 1, len(users_list)):\n",
    "                user1, user2 = users_list[i], users_list[j]\n",
    "                if G.has_edge(user1, user2):\n",
    "                    G[user1][user2]['weight'] += 1\n",
    "                    G[user1][user2]['hashtags'].add(hashtag)\n",
    "                else:\n",
    "                    G.add_edge(user1, user2, weight=1, hashtags={hashtag})\n",
    "    \n",
    "    return G\n",
    "\n",
    "# Build the network\n",
    "G = build_hashtag_network(posts_df)\n",
    "\n",
    "print(f\"Network built: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")\n",
    "print(f\"Network density: {nx.density(G):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Detect Communities and Suspicious Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find connected components (communities)\n",
    "components = list(nx.connected_components(G))\n",
    "components = [comp for comp in components if len(comp) >= 3]  # Filter small components\n",
    "\n",
    "print(f\"Found {len(components)} communities with 3+ members\")\n",
    "\n",
    "# Analyze each community\n",
    "suspicious_communities = []\n",
    "\n",
    "for i, component in enumerate(components):\n",
    "    subgraph = G.subgraph(component)\n",
    "    \n",
    "    # Calculate community metrics\n",
    "    density = nx.density(subgraph)\n",
    "    size = len(component)\n",
    "    \n",
    "    # Count user types in community\n",
    "    user_types = [G.nodes[user]['user_type'] for user in component]\n",
    "    type_counts = Counter(user_types)\n",
    "    \n",
    "    # Calculate suspicion score\n",
    "    bot_ratio = type_counts.get('bot', 0) / size\n",
    "    suspicious_ratio = type_counts.get('suspicious', 0) / size\n",
    "    \n",
    "    suspicion_score = (bot_ratio * 0.6 + suspicious_ratio * 0.3 + density * 0.1)\n",
    "    \n",
    "    community_info = {\n",
    "        'id': i,\n",
    "        'size': size,\n",
    "        'density': density,\n",
    "        'bot_ratio': bot_ratio,\n",
    "        'suspicious_ratio': suspicious_ratio,\n",
    "        'suspicion_score': suspicion_score,\n",
    "        'members': list(component),\n",
    "        'type_counts': type_counts\n",
    "    }\n",
    "    \n",
    "    if suspicion_score > 0.3:  # Threshold for suspicious communities\n",
    "        suspicious_communities.append(community_info)\n",
    "\n",
    "print(f\"\\nFound {len(suspicious_communities)} suspicious communities:\")\n",
    "for comm in suspicious_communities:\n",
    "    print(f\"Community {comm['id']}: {comm['size']} members, \"\n",
    "          f\"suspicion score: {comm['suspicion_score']:.3f}, \"\n",
    "          f\"bot ratio: {comm['bot_ratio']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create network visualization\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Position nodes using spring layout\n",
    "pos = nx.spring_layout(G, k=1, iterations=50)\n",
    "\n",
    "# Define colors for different user types\n",
    "color_map = {'normal': 'lightblue', 'bot': 'red', 'suspicious': 'orange'}\n",
    "node_colors = [color_map[G.nodes[node]['user_type']] for node in G.nodes()]\n",
    "\n",
    "# Define node sizes based on followers\n",
    "node_sizes = [G.nodes[node]['followers'] / 10 for node in G.nodes()]\n",
    "\n",
    "# Draw the network\n",
    "nx.draw(G, pos, \n",
    "        node_color=node_colors,\n",
    "        node_size=node_sizes,\n",
    "        edge_color='gray',\n",
    "        alpha=0.7,\n",
    "        with_labels=False)\n",
    "\n",
    "# Add legend\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [Patch(facecolor='lightblue', label='Normal Users'),\n",
    "                   Patch(facecolor='orange', label='Suspicious Users'),\n",
    "                   Patch(facecolor='red', label='Bot Users')]\n",
    "plt.legend(handles=legend_elements, loc='upper right')\n",
    "\n",
    "plt.title('User Interaction Network\\n(Node size = followers, Color = user type)', fontsize=16)\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Hashtag Propagation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze hashtag usage patterns\n",
    "hashtag_analysis = []\n",
    "\n",
    "for hashtag in hashtags:\n",
    "    # Get posts with this hashtag\n",
    "    hashtag_posts = posts_df[posts_df['hashtags'].apply(lambda x: hashtag in x)]\n",
    "    \n",
    "    if len(hashtag_posts) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Get user types for these posts\n",
    "    user_types = []\n",
    "    for user_id in hashtag_posts['user_id']:\n",
    "        user_type = users_df[users_df['user_id'] == user_id]['user_type'].iloc[0]\n",
    "        user_types.append(user_type)\n",
    "    \n",
    "    type_counts = Counter(user_types)\n",
    "    total_posts = len(hashtag_posts)\n",
    "    \n",
    "    # Calculate coordination metrics\n",
    "    timestamps = pd.to_datetime(hashtag_posts['timestamp'])\n",
    "    time_span = (timestamps.max() - timestamps.min()).total_seconds() / 3600  # hours\n",
    "    \n",
    "    # Coordinated posting indicator (posts within short time windows)\n",
    "    time_diffs = timestamps.sort_values().diff().dt.total_seconds() / 60  # minutes\n",
    "    coordinated_posts = sum(1 for diff in time_diffs if diff < 30)  # Posts within 30 minutes\n",
    "    \n",
    "    hashtag_analysis.append({\n",
    "        'hashtag': hashtag,\n",
    "        'total_posts': total_posts,\n",
    "        'unique_users': hashtag_posts['user_id'].nunique(),\n",
    "        'bot_posts': type_counts.get('bot', 0),\n",
    "        'suspicious_posts': type_counts.get('suspicious', 0),\n",
    "        'normal_posts': type_counts.get('normal', 0),\n",
    "        'time_span_hours': time_span,\n",
    "        'coordinated_posts': coordinated_posts,\n",
    "        'bot_ratio': type_counts.get('bot', 0) / total_posts if total_posts > 0 else 0\n",
    "    })\n",
    "\n",
    "hashtag_df = pd.DataFrame(hashtag_analysis)\n",
    "hashtag_df = hashtag_df.sort_values('bot_ratio', ascending=False)\n",
    "\n",
    "print(\"Hashtag Analysis (sorted by bot ratio):\")\n",
    "print(hashtag_df[['hashtag', 'total_posts', 'bot_ratio', 'coordinated_posts']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Hashtag Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create hashtag propagation visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Bot ratio by hashtag\n",
    "axes[0, 0].bar(hashtag_df['hashtag'], hashtag_df['bot_ratio'], color='red', alpha=0.7)\n",
    "axes[0, 0].set_title('Bot Ratio by Hashtag')\n",
    "axes[0, 0].set_ylabel('Bot Ratio')\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 2. Total posts by hashtag\n",
    "axes[0, 1].bar(hashtag_df['hashtag'], hashtag_df['total_posts'], color='blue', alpha=0.7)\n",
    "axes[0, 1].set_title('Total Posts by Hashtag')\n",
    "axes[0, 1].set_ylabel('Number of Posts')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 3. Coordinated posts\n",
    "axes[1, 0].bar(hashtag_df['hashtag'], hashtag_df['coordinated_posts'], color='orange', alpha=0.7)\n",
    "axes[1, 0].set_title('Coordinated Posts by Hashtag')\n",
    "axes[1, 0].set_ylabel('Coordinated Posts')\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 4. User engagement (unique users vs total posts)\n",
    "axes[1, 1].scatter(hashtag_df['unique_users'], hashtag_df['total_posts'], \n",
    "                   c=hashtag_df['bot_ratio'], cmap='Reds', s=100, alpha=0.7)\n",
    "axes[1, 1].set_title('User Engagement vs Bot Activity')\n",
    "axes[1, 1].set_xlabel('Unique Users')\n",
    "axes[1, 1].set_ylabel('Total Posts')\n",
    "\n",
    "# Add colorbar\n",
    "cbar = plt.colorbar(axes[1, 1].collections[0], ax=axes[1, 1])\n",
    "cbar.set_label('Bot Ratio')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Campaign Detection Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_campaigns(posts_df, users_df, min_volume=5, risk_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Detect coordinated campaigns based on multiple indicators\n",
    "    \"\"\"\n",
    "    campaigns = []\n",
    "    \n",
    "    # Analyze each hashtag\n",
    "    for hashtag in hashtags:\n",
    "        hashtag_posts = posts_df[posts_df['hashtags'].apply(lambda x: hashtag in x)]\n",
    "        \n",
    "        if len(hashtag_posts) < min_volume:\n",
    "            continue\n",
    "        \n",
    "        # Get user information\n",
    "        user_ids = hashtag_posts['user_id'].unique()\n",
    "        user_types = []\n",
    "        for uid in user_ids:\n",
    "            user_type = users_df[users_df['user_id'] == uid]['user_type'].iloc[0]\n",
    "            user_types.append(user_type)\n",
    "        \n",
    "        type_counts = Counter(user_types)\n",
    "        \n",
    "        # Calculate risk indicators\n",
    "        bot_ratio = type_counts.get('bot', 0) / len(user_ids)\n",
    "        suspicious_ratio = type_counts.get('suspicious', 0) / len(user_ids)\n",
    "        \n",
    "        # Time-based indicators\n",
    "        timestamps = pd.to_datetime(hashtag_posts['timestamp'])\n",
    "        time_span = (timestamps.max() - timestamps.min()).total_seconds() / 3600\n",
    "        posting_rate = len(hashtag_posts) / max(time_span, 1)\n",
    "        \n",
    "        # Coordination indicators\n",
    "        time_diffs = timestamps.sort_values().diff().dt.total_seconds() / 60\n",
    "        rapid_posts = sum(1 for diff in time_diffs if diff < 5)  # Posts within 5 minutes\n",
    "        coordination_score = rapid_posts / len(hashtag_posts)\n",
    "        \n",
    "        # Calculate overall risk score\n",
    "        risk_score = (\n",
    "            bot_ratio * 0.4 +\n",
    "            suspicious_ratio * 0.2 +\n",
    "            coordination_score * 0.3 +\n",
    "            min(posting_rate / 10, 0.1) * 0.1  # High posting rate\n",
    "        )\n",
    "        \n",
    "        if risk_score >= risk_threshold:\n",
    "            campaigns.append({\n",
    "                'hashtag': hashtag,\n",
    "                'volume': len(hashtag_posts),\n",
    "                'unique_users': len(user_ids),\n",
    "                'risk_score': risk_score,\n",
    "                'bot_ratio': bot_ratio,\n",
    "                'suspicious_ratio': suspicious_ratio,\n",
    "                'coordination_score': coordination_score,\n",
    "                'posting_rate': posting_rate,\n",
    "                'time_span_hours': time_span,\n",
    "                'first_post': timestamps.min(),\n",
    "                'last_post': timestamps.max()\n",
    "            })\n",
    "    \n",
    "    return sorted(campaigns, key=lambda x: x['risk_score'], reverse=True)\n",
    "\n",
    "# Detect campaigns\n",
    "detected_campaigns = detect_campaigns(posts_df, users_df)\n",
    "\n",
    "print(f\"Detected {len(detected_campaigns)} suspicious campaigns:\")\n",
    "print(\"-\" * 80)\n",
    "for campaign in detected_campaigns:\n",
    "    print(f\"Hashtag: {campaign['hashtag']}\")\n",
    "    print(f\"  Volume: {campaign['volume']} posts by {campaign['unique_users']} users\")\n",
    "    print(f\"  Risk Score: {campaign['risk_score']:.3f}\")\n",
    "    print(f\"  Bot Ratio: {campaign['bot_ratio']:.2f}\")\n",
    "    print(f\"  Coordination Score: {campaign['coordination_score']:.3f}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Interactive Network Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive network visualization with Plotly\n",
    "def create_interactive_network(G, suspicious_communities):\n",
    "    # Get positions\n",
    "    pos = nx.spring_layout(G, k=1, iterations=50)\n",
    "    \n",
    "    # Prepare node traces\n",
    "    node_trace = go.Scatter(\n",
    "        x=[pos[node][0] for node in G.nodes()],\n",
    "        y=[pos[node][1] for node in G.nodes()],\n",
    "        mode='markers',\n",
    "        hoverinfo='text',\n",
    "        text=[f\"User: {G.nodes[node]['username']}<br>\"\n",
    "              f\"Type: {G.nodes[node]['user_type']}<br>\"\n",
    "              f\"Followers: {G.nodes[node]['followers']}\"\n",
    "              for node in G.nodes()],\n",
    "        marker=dict(\n",
    "            size=[G.nodes[node]['followers'] / 50 for node in G.nodes()],\n",
    "            color=[{'normal': 0, 'suspicious': 1, 'bot': 2}[G.nodes[node]['user_type']] \n",
    "                   for node in G.nodes()],\n",
    "            colorscale=[[0, 'lightblue'], [0.5, 'orange'], [1, 'red']],\n",
    "            showscale=True,\n",
    "            colorbar=dict(title=\"User Type\",\n",
    "                         tickvals=[0, 1, 2],\n",
    "                         ticktext=[\"Normal\", \"Suspicious\", \"Bot\"])\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Prepare edge traces\n",
    "    edge_x = []\n",
    "    edge_y = []\n",
    "    for edge in G.edges():\n",
    "        x0, y0 = pos[edge[0]]\n",
    "        x1, y1 = pos[edge[1]]\n",
    "        edge_x.extend([x0, x1, None])\n",
    "        edge_y.extend([y0, y1, None])\n",
    "    \n",
    "    edge_trace = go.Scatter(\n",
    "        x=edge_x, y=edge_y,\n",
    "        line=dict(width=0.5, color='#888'),\n",
    "        hoverinfo='none',\n",
    "        mode='lines'\n",
    "    )\n",
    "    \n",
    "    # Create figure\n",
    "    fig = go.Figure(data=[edge_trace, node_trace],\n",
    "                    layout=go.Layout(\n",
    "                        title='Interactive User Network<br>Hover over nodes for details',\n",
    "                        titlefont_size=16,\n",
    "                        showlegend=False,\n",
    "                        hovermode='closest',\n",
    "                        margin=dict(b=20,l=5,r=5,t=40),\n",
    "                        annotations=[ dict(\n",
    "                            text=\"Node size = followers, Color = user type\",\n",
    "                            showarrow=False,\n",
    "                            xref=\"paper\", yref=\"paper\",\n",
    "                            x=0.005, y=-0.002,\n",
    "                            xanchor=\"left\", yanchor=\"bottom\",\n",
    "                            font=dict(size=12)\n",
    "                        )],\n",
    "                        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False))\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create and show interactive plot\n",
    "fig = create_interactive_network(G, suspicious_communities)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary and Recommendations\n",
    "\n",
    "Based on the analysis, we can identify several key patterns for campaign detection:\n",
    "\n",
    "### Key Indicators of Coordinated Campaigns:\n",
    "1. **High bot/suspicious user ratio** in hashtag usage\n",
    "2. **Coordinated timing** of posts (within short time windows)\n",
    "3. **Dense network clusters** of suspicious accounts\n",
    "4. **Rapid hashtag propagation** with artificial amplification\n",
    "\n",
    "### Recommendations for Implementation:\n",
    "1. **Real-time monitoring** of hashtag usage patterns\n",
    "2. **Network analysis** to identify suspicious communities\n",
    "3. **Time-series analysis** for coordination detection\n",
    "4. **Machine learning models** for bot detection\n",
    "5. **Multi-platform tracking** for comprehensive coverage"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",\n",
   "language": "python",\n",
   "name": "python3"\n  },\n",
   "language_info": {\n",
    "codemirror_mode": {\n",
     "name": "ipython",\n",
     "version": 3\n",
    },\n",
    "file_extension": ".py",\n",
    "mimetype": "text/x-python",\n",
    "name": "python",\n",
    "nbconvert_exporter": "python",\n",
    "pygments_lexer": "ipython3",\n",
    "version": "3.9.0"\n",
   }\n",
  },\n",
  "nbformat": 4,\n",
  "nbformat_minor": 4\n",
}